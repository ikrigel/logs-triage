# Production Logs Triage Agent

An intelligent AI-powered system that automatically investigates production logs, identifies issues, correlates them with system changes, and creates actionable support tickets with developer suggestions.

> **Deployment Ready** âœ… All Vercel configuration complete - users provide API keys through Settings UI

## Features

### Autonomous Investigation Mode
âœ¨ **AI-Powered Investigation** - Autonomous agent uses Gemini/Claude/Perplexity to analyze logs
ğŸ” **Deep Recursive Search** - Find related logs across batch IDs, user IDs, and source IDs
ğŸ”— **Change Correlation** - Link errors to deployments and configuration changes
ğŸ« **Ticket Generation** - Auto-create support tickets with intelligent suggestions

### Interactive Conversational Mode âœ¨ NEW
ğŸ’¬ **Multi-turn Chat** - Have back-and-forth conversations with the AI agent
ğŸ› ï¸ **Dynamic Tool Usage** - Agent uses tools (search, create tickets, alerts) during conversation
ğŸ“ **Persistent Sessions** - Conversation state preserved across multiple turns
ğŸ‘ï¸ **Tool Visibility** - See exactly what the agent is doing in real-time

### Platform Features
ğŸ’¾ **Local Storage** - JSON-based persistent ticket management
ğŸ“Š **Web Dashboard** - Modern UI with dark mode support
âš¡ **RESTful API** - Full-featured API for programmatic access
ğŸ” **Multi-Provider** - Support for Gemini, Claude, and Perplexity APIs

## Quick Start

### Prerequisites
- Node.js 18+
- Gemini API key (free from https://aistudio.google.com/app/apikey)

### Setup

```bash
# Clone and install
git clone <repo>
cd logs-triage
npm install

# Configure API key
# Either set environment variable:
export GOOGLE_GENERATIVE_AI_API_KEY=your_key_here

# Or create .env file:
echo "GOOGLE_GENERATIVE_AI_API_KEY=your_key_here" > .env
```

### Run the Agent

```bash
# Test specific log set (1-5)
LOG_FILE_NUMBER=1 npm run dev

# Run web server
npm run server
# Open http://localhost:3000

# Run tests
npm test
```

## Two Modes of Operation

### 1. **Run Auto Triage** (Autonomous Mode)
Automated investigation without user interaction:
- Click **"Run Auto Triage"** button
- Agent investigates logs 1-10 iterations automatically
- Creates tickets and alerts based on findings
- Perfect for: Quick automated analysis, batch processing

**Use Cases:**
- Initial log scan to identify issues
- Overnight automated triage
- Integration with monitoring systems

### 2. **Start Conversation** (Interactive Mode) âœ¨ NEW
Have a dialogue with the AI agent:
- Click **"Start Conversation"** button
- Type questions: *"What errors are in the logs?"*, *"Search for connection issues"*
- Agent responds conversationally and uses tools as needed
- Ask follow-up questions to steer investigation
- Perfect for: Guided investigation, learning, deep debugging

**Conversation Features:**
- **Multi-turn Context** - Agent remembers previous messages
- **Tool Visibility** - See what tools are being executed
- **Natural Language** - Ask questions in plain English
- **Persistent Sessions** - Conversation state saved across turns
- **Dynamic Tool Usage** - Agent decides when to search/create tickets

**Example Conversation:**
```
You: "What's happening in these logs?"
Agent: [Analyzes logs] "I see warnings about connection pool exhaustion..."

You: "Search for related errors"
Agent: [Uses search_logs tool] "Found 12 matching entries..."

You: "Should we create a ticket?"
Agent: [Uses create_ticket tool] "âœ… Created ticket TKT-1234-abc..."
```

## Log Scenarios (1-5)

1. **Healthy System** - All green logs, agent confirms no issues
2. **Warning Pollution** - Multiple deprecations and slow queries â†’ 3 tickets
3. **Critical Outage** - Payment processor failure â†’ Alert + 1 critical ticket
4. **Deployment Issue** - Database pool exhaustion after deploy â†’ Correlate change
5. **Deep Investigation** - Zendesk token expiry â†’ Recursive search needed

## Architecture

### Autonomous Agent Loop (LogTriageAgent)
```
  1. Receive last 5 logs + full log history
  2. Call LLM with available tools
  3. Execute returned tool calls
  4. Add results to memory
  5. Repeat until complete (max 10 iterations)
  6. Generate investigation summary
```

### Conversational Agent Loop (ConversationalAgent) âœ¨ NEW
```
  1. User sends message
  2. Add message to session memory
  3. Call LLM with current memory
  4. Execute any tool calls returned
  5. Add response to memory
  6. Return to user
  7. Wait for next message (session persists)
```

### Available Tools (Both Modes)
```
  â€¢ searchLogs - Deep recursive log search across IDs
  â€¢ checkRecentChanges - Correlate errors with deployments
  â€¢ createTicket - Generate support tickets with suggestions
  â€¢ alertTeam - Send alerts about critical issues
```

### Storage Layer
```
  â€¢ Sessions (conversational mode)
    - In-memory Map-based storage
    - Auto-cleanup after 1 hour inactivity
    - Serialized conversation memory

  â€¢ Tickets (both modes)
    - JSON-based local persistence
    - Atomic writes, safe concurrent access
    - Automatic backup on changes
```

### Frontend Components
```
  â€¢ Dashboard - Stats and recent activity
  â€¢ Log Viewer - Browse logs with filtering
  â€¢ Ticket Management - CRUD operations
  â€¢ Triage Panel - Both autonomous and conversational modes
  â€¢ Settings - API key configuration
```

## Project Structure

```
src/
â”œâ”€â”€ agent/                 # AI agent core
â”‚   â”œâ”€â”€ index.ts          # Main agent loop
â”‚   â”œâ”€â”€ memory.ts         # Conversation memory
â”‚   â””â”€â”€ types.ts          # Type definitions
â”œâ”€â”€ tools/                # Investigation tools
â”‚   â”œâ”€â”€ searchLogs.ts     # Log search (recursive)
â”‚   â”œâ”€â”€ checkRecentChanges.ts # Change correlation
â”‚   â”œâ”€â”€ createTicket.ts   # Ticket generation
â”‚   â”œâ”€â”€ alertTeam.ts      # Team alerts
â”‚   â””â”€â”€ index.ts          # Tool registry
â”œâ”€â”€ services/            # Business logic
â”‚   â”œâ”€â”€ aiService.ts      # LLM integration
â”‚   â”œâ”€â”€ ticketService.ts  # Ticket CRUD
â”‚   â””â”€â”€ logTriageService.ts # Entry point
â”œâ”€â”€ storage/            # Persistence
â”‚   â”œâ”€â”€ tickets.ts       # JSON storage
â”‚   â””â”€â”€ types.ts         # Storage types
â”œâ”€â”€ utils/              # Utilities
â”‚   â”œâ”€â”€ filter.ts        # Filtering engine
â”‚   â””â”€â”€ logParser.ts     # Log analysis
â”œâ”€â”€ web/                # Web application
â”‚   â”œâ”€â”€ app.ts           # Express server
â”‚   â””â”€â”€ public/          # Frontend
â”‚       â”œâ”€â”€ index.html
â”‚       â”œâ”€â”€ styles.css
â”‚       â””â”€â”€ app.js
â””â”€â”€ tests/             # Test suite
    â”œâ”€â”€ tools/
    â””â”€â”€ agent/
```

## API Endpoints

### Logs
```
GET /api/logs
GET /api/logs/:setNumber?page=1&service=x&level=ERROR&keyword=test
```

### Tickets
```
GET    /api/tickets?status=open&severity=critical
GET    /api/tickets/:id
POST   /api/tickets
PATCH  /api/tickets/:id
POST   /api/tickets/:id/comments
GET    /api/tickets/:id/close
```

### Triage
```
POST /api/triage/run
Body: { logSetNumber: 1-5 }
```

## Development

### Running Tests
```bash
npm test              # Run all tests
npm run test:ui       # Interactive mode
```

### Code Quality
- All files under 250 lines (enforces modularity)
- TypeScript for type safety
- Comprehensive test coverage
- ESLint configured

### Key Files

- **CLAUDE.md** - Detailed architecture & developer guide
- **Plan File** - Design decisions & rationale
- **vitest.config.ts** - Test configuration

## Configuration

### Environment Variables
```
GOOGLE_GENERATIVE_AI_API_KEY   # Gemini API key (required)
PORT                            # Server port (default: 3000)
LOG_FILE_NUMBER                 # Log set to test (1-5)
```

### Customization

**Change agent max iterations:**
```typescript
// In src/agent/index.ts
private maxIterations = 10;  // Adjust as needed
```

**Change storage location:**
```typescript
// In src/services/logTriageService.ts
const storage = new TicketStorage({
  filePath: '/custom/path/tickets.json'
});
```

## Troubleshooting

### API Key Not Found
```bash
# Ensure .env file exists with:
GOOGLE_GENERATIVE_AI_API_KEY=your_actual_key

# Or set environment variable:
export GOOGLE_GENERATIVE_AI_API_KEY=your_actual_key
```

### Port Already in Use
```bash
PORT=3001 npm run server
```

### Tests Failing
```bash
# Ensure dependencies installed
npm install

# Clear test cache
npm test -- --clearCache
```

### No Tickets Created
- Check agent output for errors
- Verify logs contain ERROR or WARN level entries
- Check `data/tickets.json` exists and is readable

## Performance

- **Log Search**: O(n) but fast for typical volumes
- **Recursive Search**: Efficient identifier traversal
- **LLM Calls**: Rate limited with exponential backoff
- **Storage**: Atomic writes prevent corruption
- **Memory**: Auto-compresses at 80% token usage

## Future Enhancements

- [ ] Database storage (SQLite/PostgreSQL)
- [ ] Slack/PagerDuty integration
- [ ] Custom triage rules
- [ ] Service dependency graphs
- [ ] ML anomaly detection
- [ ] Multi-tenant support
- [ ] Webhook notifications
- [ ] Historical trend analysis

## Contributing

1. Keep files under 250 lines
2. Write tests for new features
3. Follow TypeScript best practices
4. Update CLAUDE.md for architecture changes
5. Run `npm test` before committing

## License

MIT

## Resources

- [AI SDK Docs](https://sdk.vercel.ai/docs)
- [Gemini API](https://ai.google.dev/gemini-api/docs/quickstart)
- [Vercel AI SDK Tools](https://sdk.vercel.ai/docs/reference/ai-sdk-core/tool)
- [TypeScript Handbook](https://www.typescriptlang.org/docs/)

---

**ğŸ“š For detailed development guide, see [CLAUDE.md](CLAUDE.md)**